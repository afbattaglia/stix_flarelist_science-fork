{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine flare lists from different instruments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this script is to create and test functions that are instrument-specific and allow to import a dataframe containing flare lists, peak times, and flare locations. The code outside of these functions should run independently of the instrument used, so that it can be compared with STIX.\n",
    "\n",
    "[Status 30-Jun-2023]: The functions for coordinate transformations may be a bit outdated, as I created them almost two years ago. However, they still work (I updated my library recently and they seem to still function properly). Therefore, for the first version, I suggest we use these functions. We can update them later if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import spiceypy as spice\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "from astropy import units as u\n",
    "from sunpy.coordinates import Helioprojective\n",
    "from sunpy.coordinates.frames import HeliocentricEarthEcliptic, HeliographicStonyhurst\n",
    "\n",
    "# Do not show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for dealing with the SPICE kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_SPICE(path_kernel):\n",
    "    \"\"\"\n",
    "    Load the SPICE kernel that will be used to get the\n",
    "    coordinates of Solar Orbiter\n",
    "    \"\"\"\n",
    "\n",
    "    #get cwd\n",
    "    cwd=os.getcwd()\n",
    "\n",
    "    # Check if path_kernel has folder format\n",
    "    if path_kernel[-1] != '/':\n",
    "        path_kernel = path_kernel+'/'\n",
    "\n",
    "    # Change the CWD to the given path. Necessary to load correctly all kernels\n",
    "    os.chdir(path_kernel)\n",
    "\n",
    "    # Load one (or more) SPICE kernel into the program\n",
    "    spice_kernel = 'solo_ANC_soc-flown-mk.tm'\n",
    "    spice.furnsh(spice_kernel)\n",
    "\n",
    "    print()\n",
    "    print('SPICE kernels loaded correctly')\n",
    "    print()\n",
    "\n",
    "    #change back to original working directory\n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def so2hgs(coord, date, solo_hee):\n",
    "    \"\"\"\n",
    "    Takes the coordinates of the region of interest (ROI) as\n",
    "    seen from Solar Orbiter (HPC Solar Orbiter frame) and\n",
    "    transform them to hg Stonyhurst coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    # SkyCoord of the ROI as seen from Solar Orbiter\n",
    "    roi_solo_hpc = SkyCoord(coord[0]*u.arcsec, \n",
    "                            coord[1]*u.arcsec, \n",
    "                            #frame=map.coordinate_frame,\n",
    "                            obstime=date,\n",
    "                            observer=solo_hee.transform_to(HeliographicStonyhurst(obstime=date)),\n",
    "                            frame='helioprojective')\n",
    "    \n",
    "    # Assume ROI to be on the surface of the Sun\n",
    "    roi_inter = roi_solo_hpc.transform_to(HeliocentricEarthEcliptic)\n",
    "    third_dim = 1*u.Rsun\n",
    "\n",
    "    # ROI location in HEE\n",
    "    roi_hee = SkyCoord(roi_inter.lon, roi_inter.lat, third_dim, \n",
    "                       frame=HeliocentricEarthEcliptic(obstime=date))\n",
    "\n",
    "    # Since now we have the full 3D coordinate of the ROI position\n",
    "    # given in HEE, we can now transform that coordinated as seen\n",
    "    # from Solar Orbiter and give them in hg Stonyhurst coordinates\n",
    "    roi_hgc_stony = roi_hee.transform_to(HeliographicStonyhurst(obstime=date))\n",
    "    \n",
    "    return roi_hgc_stony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earth_hee(date_earth):\n",
    "    \"\"\"\n",
    "    Get the coordinates of the Earth and then return them in\n",
    "    Heliocentric Earth Ecliptic (HEE) coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Observing time (to get the Earth coordinates)\n",
    "    et_stix = spice.datetime2et(date_earth)\n",
    "\n",
    "    # Obtain the coordinates of Solar Orbiter\n",
    "    earth_hee_spice = spice.spkpos('EARTH', et_stix,\n",
    "                                     'SOLO_HEE_NASA', #  Reference frame of the output position vector of the object \n",
    "                                     'NONE', 'SUN')[0]\n",
    "    earth_hee_spice = earth_hee_spice * u.km\n",
    "\n",
    "    # Convert the coordinates to HEE\n",
    "    earth_hee = HeliocentricEarthEcliptic(earth_hee_spice, \n",
    "                                          obstime=Time(date_earth).isot, \n",
    "                                          representation_type='cartesian')\n",
    "    \n",
    "    # Return the HEE coordinates of the Earth\n",
    "    return earth_hee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_so_hee(date_so):\n",
    "    \"\"\"\n",
    "    Get the coordinates of Solar Orbiter and then return them in\n",
    "    Heliocentric Earth Ecliptic (HEE) coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Observing time (to get the SOLO coordinates)\n",
    "    et_solo = spice.datetime2et(date_so)\n",
    "\n",
    "    # Obtain the coordinates of Solar Orbiter\n",
    "    solo_hee_spice = spice.spkpos('SOLO', et_solo, 'SOLO_HEE_NASA', 'NONE', 'SUN')[0]\n",
    "    solo_hee_spice = solo_hee_spice * u.km\n",
    "\n",
    "    # Convert the coordinates to HEE\n",
    "    solo_hee = HeliocentricEarthEcliptic(solo_hee_spice, \n",
    "                                         obstime=Time(date_so).isot, \n",
    "                                         representation_type='cartesian')\n",
    "    \n",
    "    # Return the HEE coordinates of Solar Orbiter\n",
    "    return solo_hee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to import the different flare lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_stix(path_csv, check_test=False, earth_UT=False):\n",
    "    '''\n",
    "    Reads the csv file containing the STIX flare locations\n",
    "    (obtained using: https://github.com/hayesla/stix_flarelist_science)\n",
    "    Returns a pandas dataframe with the flares, the peak times and\n",
    "    the flare locations in Heliographic Stonyhurst coordinates\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_csv : str\n",
    "        Path to the csv file containing the STIX flare locations. It can be\n",
    "        a list of several csv files.\n",
    "    \n",
    "    check_test : bool, optional (default=False)\n",
    "        If True, only the flares that passed the location test are returned.\n",
    "\n",
    "    earth_UT : bool, optional (default=False)\n",
    "        If True, the peak times are returned in Earth time. If False, the\n",
    "        peak times are returned in Solar Orbiter time.\n",
    "    '''\n",
    "\n",
    "\n",
    "    # If path_csv is a list, we need to concatenate all the csv files\n",
    "    if type(path_csv) == list:\n",
    "        df = pd.DataFrame()\n",
    "        n_csv_files = len(path_csv)\n",
    "        for i in range(n_csv_files):\n",
    "            df = pd.concat([df,pd.read_csv(path_csv[i])], ignore_index=True)\n",
    "    else:\n",
    "        df = pd.read_csv(path_csv)\n",
    "    \n",
    "    # Sort the STIX dataframes by the start time of the flares\n",
    "    df.sort_values(by='peak_UTC', inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # If check_test is True, remove the failed ones\n",
    "    if check_test:\n",
    "        df = df[df['flare location test']==True]\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Save the columns of interest in lists from df\n",
    "    start_times = pd.to_datetime(df['start_UTC'].tolist()) # SO time\n",
    "    peak_times  = pd.to_datetime(df['peak_UTC'].tolist()) # SO time\n",
    "    end_times   = pd.to_datetime(df['end_UTC'].tolist()) # SO time\n",
    "    x_solo_hpc = df['x'].tolist() # arcsec, SO frame\n",
    "    y_solo_hpc = df['y'].tolist() # arcsec, SO frame\n",
    "    \n",
    "    # [Status 30-Jun-2023]: light travel time correction not yet included in the flare list\n",
    "    # Correct the all times for the light travel time\n",
    "    if earth_UT:\n",
    "        ltt_corr = pd.to_timedelta(df['ltt_corr'].tolist(), unit='s')\n",
    "        start_times += ltt_corr\n",
    "        peak_times  += ltt_corr\n",
    "        end_times   += ltt_corr\n",
    "\n",
    "    # Transform STIX coordinates in heliographic Stonyhurst [(lon, lat) in (deg, deg)]\n",
    "    lon_hgs = []\n",
    "    lat_hgs = []\n",
    "    for i in range(len(x_solo_hpc)):\n",
    "\n",
    "        # Get the HEE coordinates of the Earth at the time of the flare\n",
    "        #earth_hee = get_earth_hee(peak_times[i])\n",
    "\n",
    "        # Get the HEE coordinates of Solar Orbiter at the time of the flare\n",
    "        solo_hee = get_so_hee(peak_times[i])\n",
    "\n",
    "        # Transform the coordinates of the flare from SO hpc to heliographic Stonyhurst\n",
    "        stix_hgc_stony = so2hgs([x_solo_hpc[i], y_solo_hpc[i]], peak_times[i], solo_hee)\n",
    "        \n",
    "        # Save the coordinates\n",
    "        lon_hgs.append(stix_hgc_stony.lon.value)\n",
    "        lat_hgs.append(stix_hgc_stony.lat.value)\n",
    "\n",
    "    return df, start_times, peak_times, end_times, lon_hgs, lat_hgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_hinode(path_csv):\n",
    "    '''\n",
    "    Reads the csv file containing the Hinode flare locations\n",
    "    (exported from: https://hinode.isee.nagoya-u.ac.jp/flare_catalogue/)\n",
    "    Returns a pandas dataframe with the flares, the peak times and\n",
    "    the flare locations in Heliographic Stonyhurst coordinates\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_csv : str\n",
    "        Path to the csv file containing the Hinode flare locations. It can be\n",
    "        a list of several csv files.\n",
    "    '''\n",
    "\n",
    "    # If path_csv is a list, we need to concatenate all the csv files\n",
    "    if type(path_csv) == list:\n",
    "        df = pd.DataFrame()\n",
    "        n_csv_files = len(path_csv)\n",
    "        for i in range(n_csv_files):\n",
    "            df = pd.concat([df,pd.read_csv(path_csv[i])], ignore_index=True)\n",
    "    else:\n",
    "        df = pd.read_csv(path_csv)\n",
    "\n",
    "    # Sort the Hinode dataframes by the start time of the flares\n",
    "    df.sort_values(by='start', inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Remove the flares that have 0 in all XRT, EIS and SOT columns\n",
    "    df = df[(df['XRT']!=0) | (df['EIS']!=0) | (df['SP']!=0) | (df['FG']!=0)]\n",
    "\n",
    "    # Save the columns of interest in lists from df\n",
    "    peak_times   = pd.to_datetime(df['peak'].tolist()) # Earth time\n",
    "    ar_location = df['AR location'].tolist() # Stonyhurst heliographic coord\n",
    "\n",
    "    # Transform Hinode coordinates in heliographic Stonyhurst [(lon, lat) in (deg, deg)]\n",
    "    lon_hgs = []\n",
    "    lat_hgs = []\n",
    "    for i in range(len(ar_location)):\n",
    "\n",
    "        sign_ns = 1\n",
    "        sign_ew = 1\n",
    "        if ar_location[i][0] == 'S': sign_ns = -1\n",
    "        if ar_location[i][3] == 'E': sign_ew = -1\n",
    "        coord_ns = float(ar_location[i][1:3])\n",
    "        coord_ew = float(ar_location[i][4:6])\n",
    "        lon = (sign_ew * coord_ew) #* u.deg\n",
    "        lat = (sign_ns * coord_ns) #* u.deg\n",
    "\n",
    "        # Convert the coordinates from Stonyhurst to HPC\n",
    "        #coord = SkyCoord(lon*u.deg, lat*u.deg, frame=HeliographicStonyhurst, obstime=xrt_peak_time[i])\n",
    "        #coord_hpc = coord.transform_to(Helioprojective(observer='earth', obstime=xrt_peak_time[i]))\n",
    "        \n",
    "        # Save the coordinates\n",
    "        lon_hgs.append(lon)\n",
    "        lat_hgs.append(lat)\n",
    "        \n",
    "    return df, peak_times, lon_hgs, lat_hgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the csv file containing the STIX locations\n",
    "#path_csv_stix_flares = '/home/afbattaglia/Documents/ETHZ/PhD/Flares/Davos-Visit/stix-flare-locations/flare_location_df_first_pass_duplicates_v2.csv'\n",
    "path_csv_stix_flares = '/home/afbattaglia/Documents/ETHZ/PhD/Codes/Python/test_flare-list/full-flarelist-with-paths-and-locations_no-NaNs.csv'\n",
    "\n",
    "# Path to the folder containing the csv files with the Hinode locations\n",
    "folder_csv_hinode_flares = '/home/afbattaglia/Documents/ETHZ/PhD/Flares/Davos-Visit/stix-flare-locations/hinode/'\n",
    "\n",
    "# SPICE kernel\n",
    "# Please visit: https://www.cosmos.esa.int/web/spice/solar_orbiter\n",
    "path_spice = '/home/afbattaglia/Software/spice-kernels/solar-orbiter/kernels/mk'\n",
    "\n",
    "# Threshold of the distance between the STIX and Hinode locations\n",
    "# to consider them as the same flare\n",
    "threshold_loc = 15   # degrees\n",
    "\n",
    "# Time margin to consider the STIX and Hinode times as the same, \n",
    "# given in pandas.Timedelta format\n",
    "threshold_time = pd.Timedelta('1 hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/afbattaglia/Documents/ETHZ/PhD/Flares/Davos-Visit/stix-flare-locations/hinode/Hinode-Flare-Catalogue_2021.csv',\n",
       " '/home/afbattaglia/Documents/ETHZ/PhD/Flares/Davos-Visit/stix-flare-locations/hinode/Hinode-Flare-Catalogue_2022.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all csv filed contained in the fodler_csv_hinode_flares\n",
    "list_csv_hinode_flares = []\n",
    "for file in os.listdir(folder_csv_hinode_flares):\n",
    "    if file.endswith(\".csv\"):\n",
    "        list_csv_hinode_flares.append(folder_csv_hinode_flares+file)\n",
    "list_csv_hinode_flares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPICE kernels loaded correctly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the SPICE kernel\n",
    "load_SPICE(path_spice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the flare lists\n",
    "df_stix, start_times_stix, peak_times_stix, end_times_stix, stix_lon_hgs, stix_lat_hgs = import_stix(path_csv_stix_flares, check_test=False, earth_UT=False)\n",
    "df, peak_times, lon_hgs, lat_hgs = import_hinode(list_csv_hinode_flares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare times and locations of the different instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the XRT flares that are within the STIX time window and location\n",
    "combined_flare_list = pd.DataFrame()\n",
    "for i in range(len(peak_times)):\n",
    "    \n",
    "    # First of all, we need to find the index of the STIX flare that is\n",
    "    # closest to the Hinode flare\n",
    "    time_diff = abs(peak_times[i] - peak_times_stix)\n",
    "    idx_stix = np.where(time_diff == np.min(time_diff))[0][0]\n",
    "\n",
    "    # Then, we need to check if the start and end times of the other instrument's flare \n",
    "    # are within the STIX time window plus the time margin\n",
    "    check = False\n",
    "    if (peak_times[i] >= start_times_stix[idx_stix]   - threshold_time) and (peak_times[i] <= end_times_stix[idx_stix]   + threshold_time): check = True\n",
    "    if (peak_times[i] >= start_times_stix[idx_stix-1] - threshold_time) and (peak_times[i] <= end_times_stix[idx_stix-1] + threshold_time): check = True\n",
    "    if (peak_times[i] >= start_times_stix[idx_stix+1] - threshold_time) and (peak_times[i] <= end_times_stix[idx_stix+1] + threshold_time): check = True\n",
    "    \n",
    "    if check:\n",
    "            \n",
    "        # Now check if the location of the flare is within the\n",
    "        # threshold_loc from the STIX flare in heliographic Stonyhurst coordinates\n",
    "        if (abs(lon_hgs[i] - stix_lon_hgs[idx_stix]) <= threshold_loc) and (abs(lat_hgs[i] - stix_lat_hgs[idx_stix]) <= threshold_loc):\n",
    "            # Append the i-th element to xrt_stix_flares\n",
    "            combined_flare_list = combined_flare_list._append(df.iloc[i])\n",
    "\n",
    "# Reset the index of the combined flare list\n",
    "combined_flare_list.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event number</th>\n",
       "      <th>start</th>\n",
       "      <th>peak</th>\n",
       "      <th>end</th>\n",
       "      <th>AR location</th>\n",
       "      <th>X-ray class</th>\n",
       "      <th>FG</th>\n",
       "      <th>SP</th>\n",
       "      <th>XRT</th>\n",
       "      <th>EIS</th>\n",
       "      <th>DARTS</th>\n",
       "      <th>RHESSI</th>\n",
       "      <th>Suzaku/WAM</th>\n",
       "      <th>NoRH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176310</td>\n",
       "      <td>2021/04/24 15:35</td>\n",
       "      <td>2021/04/24 15:59</td>\n",
       "      <td>2021/04/24 16:10</td>\n",
       "      <td>S21E12</td>\n",
       "      <td>B2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176320</td>\n",
       "      <td>2021/04/24 16:45</td>\n",
       "      <td>2021/04/24 16:53</td>\n",
       "      <td>2021/04/24 16:58</td>\n",
       "      <td>S21E12</td>\n",
       "      <td>B6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176340</td>\n",
       "      <td>2021/04/24 17:33</td>\n",
       "      <td>2021/04/24 17:37</td>\n",
       "      <td>2021/04/24 17:42</td>\n",
       "      <td>S21E11</td>\n",
       "      <td>B1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176930</td>\n",
       "      <td>2021/05/05 22:25</td>\n",
       "      <td>2021/05/05 22:31</td>\n",
       "      <td>2021/05/05 22:38</td>\n",
       "      <td>N15E88</td>\n",
       "      <td>B1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176940</td>\n",
       "      <td>2021/05/05 22:43</td>\n",
       "      <td>2021/05/05 22:48</td>\n",
       "      <td>2021/05/05 22:54</td>\n",
       "      <td>N17E88</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>204720</td>\n",
       "      <td>2022/05/11 18:13</td>\n",
       "      <td>2022/05/11 18:58</td>\n",
       "      <td>2022/05/11 19:27</td>\n",
       "      <td>S17W89</td>\n",
       "      <td>M2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>205760</td>\n",
       "      <td>2022/05/26 03:27</td>\n",
       "      <td>2022/05/26 03:42</td>\n",
       "      <td>2022/05/26 03:52</td>\n",
       "      <td>N19W89</td>\n",
       "      <td>C2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>207380</td>\n",
       "      <td>2022/06/24 18:37</td>\n",
       "      <td>2022/06/24 18:44</td>\n",
       "      <td>2022/06/24 18:51</td>\n",
       "      <td>S17W79</td>\n",
       "      <td>C1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>207500</td>\n",
       "      <td>2022/06/26 03:10</td>\n",
       "      <td>2022/06/26 03:21</td>\n",
       "      <td>2022/06/26 03:29</td>\n",
       "      <td>N22W74</td>\n",
       "      <td>C1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>207640</td>\n",
       "      <td>2022/06/28 03:51</td>\n",
       "      <td>2022/06/28 03:58</td>\n",
       "      <td>2022/06/28 04:02</td>\n",
       "      <td>N15W89</td>\n",
       "      <td>B6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Event number             start              peak               end  \\\n",
       "0          176310  2021/04/24 15:35  2021/04/24 15:59  2021/04/24 16:10   \n",
       "1          176320  2021/04/24 16:45  2021/04/24 16:53  2021/04/24 16:58   \n",
       "2          176340  2021/04/24 17:33  2021/04/24 17:37  2021/04/24 17:42   \n",
       "3          176930  2021/05/05 22:25  2021/05/05 22:31  2021/05/05 22:38   \n",
       "4          176940  2021/05/05 22:43  2021/05/05 22:48  2021/05/05 22:54   \n",
       "..            ...               ...               ...               ...   \n",
       "267        204720  2022/05/11 18:13  2022/05/11 18:58  2022/05/11 19:27   \n",
       "268        205760  2022/05/26 03:27  2022/05/26 03:42  2022/05/26 03:52   \n",
       "269        207380  2022/06/24 18:37  2022/06/24 18:44  2022/06/24 18:51   \n",
       "270        207500  2022/06/26 03:10  2022/06/26 03:21  2022/06/26 03:29   \n",
       "271        207640  2022/06/28 03:51  2022/06/28 03:58  2022/06/28 04:02   \n",
       "\n",
       "    AR location X-ray class  FG  SP  XRT  EIS  DARTS RHESSI  Suzaku/WAM  NoRH  \n",
       "0        S21E12        B2.0   0   0   65    0    NaN     no         NaN   NaN  \n",
       "1        S21E12        B6.9   0   0   35    0    NaN     no         NaN   NaN  \n",
       "2        S21E11        B1.7   0   0   25    0    NaN     no         NaN   NaN  \n",
       "3        N15E88        B1.2   0   0   42    0    NaN     no         NaN   NaN  \n",
       "4        N17E88        B1.1   0   0   35    0    NaN     no         NaN   NaN  \n",
       "..          ...         ...  ..  ..  ...  ...    ...    ...         ...   ...  \n",
       "267      S17W89        M2.6   0   0  284    0    NaN     no         NaN   NaN  \n",
       "268      N19W89        C2.9   0   0    5    0    NaN     no         NaN   NaN  \n",
       "269      S17W79        C1.1   0   0   30    0    NaN     no         NaN   NaN  \n",
       "270      N22W74        C1.5   0   0   62    0    NaN     no         NaN   NaN  \n",
       "271      N15W89        B6.9   0   0   13    0    NaN     no         NaN   NaN  \n",
       "\n",
       "[272 rows x 14 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_flare_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stix_flare_list",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
